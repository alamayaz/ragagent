{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "id": "0FmMzHEfo_b4",
    "outputId": "56078876-9274-4b42-b5ce-8bb4c84ccec6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.1)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.31.0)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.33.2)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.14.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.116.0)\n",
      "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.0)\n",
      "Requirement already satisfied: gradio-client==1.10.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.1)\n",
      "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
      "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
      "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.7)\n",
      "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
      "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.12.2)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.3)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.35.0)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (2025.3.2)\n",
      "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (15.0.1)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.7.9)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl (31.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, faiss-cpu, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed faiss-cpu-1.11.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "8fee5175a069492a9b2e0f1ebacfaa68",
       "pip_warning": {
        "packages": [
         "nvidia"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install pandas sentence-transformers transformers faiss-cpu gradio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "d4tvT7BqpRu9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Change the filename below if needed, e.g. if your uploaded file name is different.\n",
    "train = pd.read_csv('Training Dataset.csv')\n",
    "\n",
    "# Create text chunks: column stats + sample rows + rule\n",
    "chunks = []\n",
    "for col in train.columns:\n",
    "    desc = f\"Column '{col}': {train[col].describe().to_dict()}\"\n",
    "    chunks.append(desc)\n",
    "\n",
    "for i in range(min(5, len(train))):\n",
    "    row = train.iloc[i].to_dict()\n",
    "    chunks.append(f\"Sample Row {i+1}: {row}\")\n",
    "\n",
    "chunks.append(\"Rule: Loan approval is influenced by income, credit history, and employment status.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3F9GaWbNtfSp"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493,
     "referenced_widgets": [
      "308916a536e54dfd95fee1907d894f16",
      "2f668f15060649e2992a8b60167976c4",
      "5683683b57634f748b07073bccde121c",
      "0feaef071808492bb464064a07a3c467",
      "9d5da15174444688973ffc9e012ed7cf",
      "3eb0f4fcc8914c75bfc902bc0087e477",
      "7e0735388411455e9466bf7a24f3bffe",
      "e6210adbd7274bebb8512e273e0d810f",
      "616994d17e23405d851e4f245648a2c4",
      "23c3eb129a154597b010ccac4b9b4e8f",
      "43b1114a877f45a190aa2d231cba7ba1",
      "f736008bf8ca45d4a9a96c231b65ee39",
      "186358d38fa64adfa1ef79699bc276bb",
      "5d438580fa4e4bbabd5be16be6f34f5c",
      "98b844d5fd6347f387f0a9d1a1e95e0b",
      "1dec3c2541df49ea959db312defc3d9f",
      "069cab637e4f485581c99268bd3140f4",
      "cc442571dc5944389d604b53d336fa48",
      "661f4684600e43f1bfef89493feb50e7",
      "d1dab3682e4e4a6888443acd36590c4b",
      "1b24ec776b4d46868d40336c01dba0d1",
      "0d2844e61d34431b99794fe810406748",
      "e15967c381874182b5ff9e500b9c4491",
      "d9a89d3a876744838a1aba7475f967a1",
      "53e11d3129e64f7c8021dddda7446435",
      "37ab1a3543c340f0b2b5dbeffaedd659",
      "2b27601272c14e2fb9aa38182d7bca05",
      "b5f290b3db5743679847857eeca718fb",
      "69fa202f63204040b53ce1352967d789",
      "f5ad895411fd4e4396ec3da48b54b37b",
      "74fb1b538220404fa00ade482328c7bf",
      "01311b2c2f034ad689f201789ede1b52",
      "3ca10012a4394bf290a555681f4f3624",
      "8c6274423054492d93188852efe8669e",
      "c7cc6cf2bdb344b1b503ab51944e8af3",
      "f79623c106454a01aa7eeace285ee987",
      "851b133a0f074be6bdd73987ef957520",
      "a1a1274047134be3b76c16133966315b",
      "b677173e187a408abe487310040896a1",
      "e31085b1fc864cac9aa7942b52bd968b",
      "696e4b27517345d5bc0ad429d07dbbf2",
      "aa0f919bd4a54b3f94f7f55466deca06",
      "0f110214ce2a4034b316f5ce33a8ca7b",
      "0c619a51b50d422d9597ceb956ec7033",
      "9e960020e3d74c9fbbeda544e494a50d",
      "43eeb7503f35481c9d7af1a4bd4d492d",
      "0a916b9f54304bd1a84996ab4696fa7f",
      "95b63b7b7c2d4ffa8ff1918820cba2e4",
      "391d98e71f3b46e59e6f7fc94eb38ab5",
      "746901058ba34a688df57e9a5e5a4f90",
      "587874d2b17c47b7adaa0f5012195052",
      "743c5b8e38bd48d08aa9914a44b20002",
      "22bb04aad48d4689a2bc2558af0983fb",
      "1cbc0e95797e4426ad9b2dc5232fb0c6",
      "fc82a5e3ff114b49a21fd594496d89c5",
      "ad76cec773004f4d846ce0b644d56e48",
      "e7db4b672a2e478981b4088ce35617ff",
      "a9cc5c717c4343dd94bf0a74d0805604",
      "44c334063eb6480a99647541946a083d",
      "ed82dcf5ad394528b3a08674656ca2f3",
      "27a4779471cc4825872488bc3e8ab575",
      "f82363d19ccd4c86ab8e007096a3b131",
      "ff7f5f0e7644475c94ff985850a5ee87",
      "02db8dbb794d4808ae461d66ea6d0cbb",
      "297eb13d288b46018ce75b71edec7242",
      "2ee48e750de44b8fa0ebff00247395e3",
      "577611366f8d401fbd8bc4814e438f89",
      "f6bdd2d1ecf74d80a077d5f79a35d0d1",
      "f3ce0ca34a02414ca950737c0b702de0",
      "ae7530120b114109b92a19755c86d749",
      "0dd4cc45e9a5461294b4f2f1e3b526b2",
      "ebf8380fca854fcab732b5ef7eccd1fa",
      "17148aeb2e424c99a46b9c111e333878",
      "26ec4e97eeb04863b887f770bc06a3d4",
      "b7f8cf7da6c14641a3b4196047d3454f",
      "aa6abf06ce604e728bede8d68c098a84",
      "e6814da158394c9a8e6b8c57887735b2",
      "8b029fc26b2e4611b62fa1ba29bac7fc",
      "b40f7cf724614db78ab0104c7d7c504c",
      "d63c3e006e11433aaeabcabae44a315c",
      "99c17cc06fd745e6b9e2efd2b6d9d295",
      "dbddaba66f7e475aac7e2b00144419cc",
      "0ffb440ecc2a4fabb34fb77761286340",
      "291f732b6558416d8487fcaa51757751",
      "883ca3df602f4682bdfa4e5087cb8166",
      "ecd0e6705be34e2fb490c7c81a97c047",
      "0a6498d0402643e39442819648b78003",
      "865c5b2e74924093a69166d5867d24ff",
      "1948e89c4cb6404582ef7522e110af2e",
      "ecbe169f8ae549b48211396ec0f80cd2",
      "6e8e69afad3b4a18a885e1db2c021bec",
      "43eca7bad81a432a93ab3fc3268e922d",
      "2eade15328434427980ce255ad8f0350",
      "d6cc1ebf150c4234a54061623c28ed2c",
      "760b7c59864b444da9f3e0aec1086786",
      "1934d9e6d46d4d80a72e004d502c75e0",
      "1760d1af044e4823bb02a695eeba7bcc",
      "7f8326881d514d1382587e4b9f4df4eb",
      "8d87a60abcdb429e829ff07fbc4f5512",
      "1287065b972c4f04b1d122de970fb9aa",
      "0bc531bef3dc4a719342cd159a4c2020",
      "d2851c1514574fb39e4c0b642ed99c9b",
      "c225fcd89cb84d29a12070a141957369",
      "4c60dc61c131454cb6d3c50378086965",
      "9b9b0ad537db47bba9e172f8b72fc05f",
      "e4a7d0a29d65485d8972c3edecaeb074",
      "23d00fcce6924337b96863a75f264c4e",
      "9a9a73b7b9544c409e4afb5df341320f",
      "9f61de19133942549c073130ae14f014",
      "b51da96138d647c4827318133a81eaf9",
      "6ec5322f86124d9fb070b8e32e53b580",
      "c988ac51b1cf451183e88aad12df1622",
      "d45ad3810ff64ac9b1d9833c51f768dc",
      "07eb9dc06ab74573ae8446428f40a0d1",
      "b43bb66a6a634c71b7f44050bc5ff5d7",
      "b4b193cdaafb4066bd908d1e4e7d040b",
      "77e2062229264924871099a17886f1c0",
      "276b8e7fe68d4716bcb0faeff992eb9b",
      "d297f6070732406fad003c224168bebd",
      "58e0107b68404699b1db93362ab1bda4",
      "c7eb94af7a6d48ae957c563c8b9a1cfa"
     ]
    },
    "id": "pZusG0kupU10",
    "outputId": "a4862798-bffe-4a30-ddba-e510a642aea3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "308916a536e54dfd95fee1907d894f16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f736008bf8ca45d4a9a96c231b65ee39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e15967c381874182b5ff9e500b9c4491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c6274423054492d93188852efe8669e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e960020e3d74c9fbbeda544e494a50d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad76cec773004f4d846ce0b644d56e48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "577611366f8d401fbd8bc4814e438f89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b029fc26b2e4611b62fa1ba29bac7fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1948e89c4cb6404582ef7522e110af2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1287065b972c4f04b1d122de970fb9aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ec5322f86124d9fb070b8e32e53b580",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "chunk_embeddings = embedder.encode(chunks, convert_to_numpy=True)\n",
    "\n",
    "dimension = chunk_embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(chunk_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258,
     "referenced_widgets": [
      "ef6a6d5176ca4d0484e66f30d6fc0f33",
      "bc184b61ad0e48008653e39968c5c6c3",
      "19c759766a6041a3963caacf359014e1",
      "fb5cc65f68e14234accda50a651c28e1",
      "09457ca048394f0da13fbd741971d671",
      "051255a3f41b4ec584f0df13c7342d4b",
      "938cc33ed5754fcebc738775ed7f56df",
      "a74c9c5804e945df9d672e80ec31d03d",
      "6dbce24a08f141d7856e7d0916c8b4af",
      "c1b64da609724692ab4b8a976869e450",
      "e87bf02c3e264e46a5ab534dd6c76d33",
      "2d365c885d384df8a42e6c4f3faec654",
      "88ee6c94d865457cafb284d3cb87dbb1",
      "abd81c1dcdda4fedbbced883c2e536fe",
      "494650a6122e4b4997e487c5dc88a021",
      "49d51c016c914323923db2ef24469c82",
      "34276512e5b74e418e5c553724f13486",
      "c2108b9c4c224dec87eeb530ec112b2d",
      "c699e3e2cc1f4b7684a1d73966c3d44e",
      "4b1f76d7a0944101a674eb8c69bc04a5",
      "48ef4ef0ac084607b3cde4fad7af17fc",
      "272191710dab4b0da04c0bb814779139",
      "e1862be750f745879ab6c27473dfd7b8",
      "30caf4ab1c9b4872a40f64d8bfde6c55",
      "81ca4bba63854ce898121d086ba0b358",
      "abaa882a83fe47048b3bb39bbf19969c",
      "3cf8648df8e8474e9612daf3006f9aeb",
      "79e30d39c5e547d59c7301ce845a36c8",
      "909b156cfe3846b7bc7f56a404180646",
      "fecf5093bf5c455ab5abc5ca92f49f6e",
      "ea35733029d947ceac72a09d0e54642c",
      "ca0cf2fbdc7d4b26982778aa52482e43",
      "f9923677c1204f56a8fe9b60b2e532cd",
      "62ae169a61404b0188c97ec6f9feff70",
      "dfab7fa0dc5f4c71aff5613230b4461b",
      "07e1abe283224344a424fd69b5892da2",
      "2ffd571f5e144ec6a23afaa7103f39b4",
      "d59dd1683b644486810d71ff75425f35",
      "c8e47bdb8abd48d7abee6c0112490714",
      "a8b07b768a704320ad70cf2256b9f901",
      "0c732dbd83194db7a04175e1e8bb7006",
      "d6d83c6aac5f44238c1dc7790c9634cf",
      "a800bbb6c49b49eea583218f520b030e",
      "9c36cb22316344018b7ec6a93786ffd5",
      "00a73b84587b41bcaebb32238d439c71",
      "716ba94c77b04e0e94822fd7b9560e26",
      "5ce58c2b157743f4a52c0ff3baeaa3b7",
      "deffb1abde7144689d9cbd06eaaaa215",
      "efb578c83c644839a03fff567e194c6d",
      "5b91d13750dd4ae7bada6492c8bcee1f",
      "63786b3bbff94a899adb659471f357a1",
      "248158edcca84fc4b2675b006e4d577a",
      "4bdf6f993e1441649078549b472f4a41",
      "a0ac6c5b50d04fe3a9a58b4d79d3fbfa",
      "e06485d515a74a1dbc6afd56f025f993",
      "f4044b0b5b604dd785f84d259204622e",
      "fb8c07b8909b455196707dfd65381187",
      "bfe5cb56e42a45e5aef73ffea44122eb",
      "f1b06df05c57453cbef922b5791e05e9",
      "40928aa727264570a5b2ccf85a04d4cc",
      "a103108f47ee4d648c19b89c210d88fe",
      "f000ef80ec994902ba9570f4671ee43b",
      "1d977a8b0d7e4e6690fed4d366df3158",
      "bec8282571914ccebf0bc6b81bf7bd99",
      "6680194dc0fe421f9b519addb0c98cc3",
      "1aea877b918d4dada41031aafb127825",
      "378a3740b6f94c6aac37e1c5db7fd877",
      "aa3297f0c826444f8054b8a515f4ff73",
      "9e1bbf7c24a14fa3ac709fa5514996e4",
      "87cc775c43704058a110d7424131c688",
      "f4c7951478f645288ac7abea8b7f7ae1",
      "3e9d74f2f8524fa084b8cf2b93512a8c",
      "84d86826a8e9444ba52cb84cacddd3de",
      "89904370325843a69494424235601fa8",
      "672fe6a42116415cb825fe4ef4354c23",
      "74b1ce717ef1461fa669ff570fb1a1d4",
      "2ec33c380169492b98aa8553c1213769"
     ]
    },
    "id": "mVfY0LCapXiJ",
    "outputId": "95b54465-103d-40fd-eef6-84188c27d976"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef6a6d5176ca4d0484e66f30d6fc0f33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d365c885d384df8a42e6c4f3faec654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1862be750f745879ab6c27473dfd7b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62ae169a61404b0188c97ec6f9feff70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00a73b84587b41bcaebb32238d439c71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4044b0b5b604dd785f84d259204622e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "378a3740b6f94c6aac37e1c5db7fd877",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "llm = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
    "    tokenizer=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
    "    max_new_tokens=256,\n",
    "    temperature=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 645
    },
    "id": "Taowj_hwwGBe",
    "outputId": "5a2d7af0-d4df-4318-bf89-28817e867f30"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/gradio/chat_interface.py:339: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  self.chatbot = Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "* Running on public URL: https://7f1620b9c15cdd1747.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://7f1620b9c15cdd1747.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def retrieve_context(query, k=3):\n",
    "    query_vec = embedder.encode([query], convert_to_numpy=True)\n",
    "    D, I = index.search(query_vec, k)\n",
    "    return [chunks[i] for i in I[0]]\n",
    "\n",
    "def rag_answer(message, history):\n",
    "    # Add previous conversation (last 3 turns)\n",
    "    history_text = \"\"\n",
    "    for user_msg, bot_msg in history[-3:]:\n",
    "        history_text += f\"User: {user_msg}\\nBot: {bot_msg}\\n\"\n",
    "    context = retrieve_context(message, k=3)\n",
    "    prompt = f\"\"\"You are an assistant for questions about a loan approval dataset.\n",
    "Previous conversation:\n",
    "{history_text}\n",
    "User: {message}\n",
    "Based on the context below, answer the user's question.\n",
    "\n",
    "Context:\n",
    "{chr(10).join(context)}\n",
    "\n",
    "Answer:\"\"\"\n",
    "    result = llm(prompt)\n",
    "    output = result[0]['generated_text']\n",
    "    if \"Answer:\" in output:\n",
    "        output = output.split(\"Answer:\")[-1].strip()\n",
    "    return output\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "gr.ChatInterface(\n",
    "    fn=rag_answer,\n",
    "    title=\"Loan Approval Q&A Chatbot\",\n",
    "    description=\"Ask anything about the loan approval prediction dataset!\"\n",
    ").launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B432ze5fx5yB",
    "outputId": "db3bcb10-6277-4db7-9821-309933d9813c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loan approval is influenced by income, credit history, and employment status. The sample row with the highest income is Row 3, and the sample row with the highest credit history is Row 4. The sample row with the highest employment status is Row 3.\n"
     ]
    }
   ],
   "source": [
    "print(rag_answer(\"What features are most important for loan approval?\",\"\"))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
